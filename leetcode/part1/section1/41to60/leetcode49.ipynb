{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26d1db07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def groupAnagrams(strs: list[str]) -> list[list[str]]:\n",
    "    anagram_groups = defaultdict(list)\n",
    "    \n",
    "    for s in strs:\n",
    "        sorted_s = \"\".join(sorted(s))\n",
    "        anagram_groups[sorted_s].append(s)\n",
    "        \n",
    "    return list(anagram_groups.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b86bb7d",
   "metadata": {},
   "source": [
    "The LeetCode problem 49, \"Group Anagrams,\" is a classic string manipulation and hashing challenge. It requires grouping a given array of strings (`strs`) into sub-lists such that all strings within each sub-list are **anagrams** of one another. An anagram is formed by rearranging the letters of another word or phrase, using all the original letters exactly once. The overall goal is to return a list of these groups.\n",
    "\n",
    "---\n",
    "\n",
    "### **The Fundamental Challenge: Identifying Anagrams**\n",
    "\n",
    "The core of the problem is devising an efficient way to determine if two arbitrary strings, say $s_1$ and $s_2$, are anagrams. Since the order of the letters does not matter, but the *count* of each letter must be identical, any two anagrams must share the same unique identifier or \"canonical form.\" The most straightforward way to solve this involves mapping, where the canonical form acts as the key in a hash map, and the value is the list of strings that map to that key.\n",
    "\n",
    "---\n",
    "\n",
    "### **Strategy 1: Sorting as the Canonical Key**\n",
    "\n",
    "The simplest and most common method to generate a unique canonical form for any group of anagrams is to **sort the characters** of the string alphabetically.\n",
    "\n",
    "1.  **Key Generation:** Given a string $s$, we convert it to a character array, sort the array, and then convert the sorted array back into a string. For example, \"eat\", \"tea\", and \"ate\" all sort to the canonical key \"aet\".\n",
    "2.  **Mapping:** We initialize a hash map (e.g., `Map<String, List<String>>`). We iterate through every string in the input array:\n",
    "    * Generate the sorted canonical key $K$.\n",
    "    * Use $K$ as the key in the hash map.\n",
    "    * Append the original string $s$ to the list associated with key $K$.\n",
    "\n",
    "After processing all input strings, the values of the hash map represent the final required groups of anagrams.\n",
    "\n",
    "---\n",
    "\n",
    "### **Strategy 2: Character Counting as the Canonical Key (Tuple/String Hashing)**\n",
    "\n",
    "While sorting works, it involves $O(L \\log L)$ time complexity for sorting a string of length $L$. Since the strings contain only lowercase English letters (26 possibilities), we can achieve $O(L)$ time complexity for key generation by using **character counting**.\n",
    "\n",
    "1.  **Count Array:** For each string, we create a count array (size 26) to store the frequency of each letter ('a' through 'z').\n",
    "2.  **Key Generation:** This count array itself is used to form the canonical key. A common way to serialize this is to create a string or tuple representing the counts and their associated letters, for example, $\\text{\"\\#1a\\#1e\\#1t\"}$ for \"eat\" (meaning one 'a', one 'e', one 't'). This unique string serves as the key $K$ in the hash map.\n",
    "3.  **Mapping:** Similar to the sorting method, the original string is appended to the list associated with this count-based key $K$.\n",
    "\n",
    "This approach is theoretically faster for very long strings, as the key generation is linear $O(L)$, resulting in an overall complexity improvement for the key generation phase.\n",
    "\n",
    "---\n",
    "\n",
    "### **The Overall Algorithm and Complexity**\n",
    "\n",
    "The overall process requires iterating through the input array once, performing the key generation, and then performing the map operation (insert/append).\n",
    "\n",
    "1.  **Initialization:** Create the hash map.\n",
    "2.  **Iteration:** Loop through all $N$ strings in the input array.\n",
    "3.  **Key Generation:** Choose either the Sorting or Counting method to generate the canonical key $K$.\n",
    "4.  **Grouping:** Insert the original string into the list associated with $K$ in the hash map.\n",
    "5.  **Result:** Extract all values (the lists of anagrams) from the hash map and return them as a final list of lists. \n",
    "\n",
    "---\n",
    "\n",
    "### **Complexity Analysis**\n",
    "\n",
    "Let $N$ be the number of strings in the input array, and $L$ be the maximum length of any string. $A$ is the size of the alphabet (26 for lowercase English letters).\n",
    "\n",
    "* **Time Complexity (Sorting Method):** The dominant step is sorting the characters of all $N$ strings. Each sort takes $O(L \\log L)$. The overall time complexity is $O(N \\cdot L \\log L)$.\n",
    "* **Time Complexity (Counting Method):** The dominant step is generating the count array for all $N$ strings, which takes $O(L)$ time for each string. The serialization to a key takes $O(A)$ or $O(L)$ time depending on the method. Since $A$ is a constant (26), the overall time complexity is $O(N \\cdot L)$. This is generally considered the more efficient solution, especially for a large number of strings with long lengths.\n",
    "* **Space Complexity:** The space is primarily determined by the hash map, which stores all $N$ input strings, plus the space needed for the $O(N)$ keys. The total space complexity is $O(N \\cdot L)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfe7068",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
