## Pyodide

```pyodide height="10"
# Type here


```
## Run

```pyodide
{% 
    include "../python_run/_3.py" 
    preserve-includer-indent=false 
%}
```

## Solution

```python
{% 
    include "../python_mod/_3.py" 
    preserve-includer-indent=false 
%}
```

<a target="__blank" href="https://leetcode.com/problems/longest-substring-without-repeating-characters/"><input class="verify-button" type="button" value="Verify"/></a>

## Function Description

::: _3.Solution
    handler: python
    options:
        # Display the docstring for the Solution class itself
        #show_root_heading: true
        # Display all public members (like the twoSum method)
        members: true

## Explanation

The "Longest Substring Without Repeating Characters" problem is a foundational algorithmic challenge that requires finding the maximum length of a substring within a given input string $s$ that contains no repeated characters. This problem is an excellent measure of a developer's ability to identify and implement time-efficient solutions. While a simple brute-force check of all possible substrings yields a highly inefficient time complexity of $O(n^3)$ or a slightly better $O(n^2)$, professional standards demand an optimized solution that can handle large inputs, specifically one that operates in linear time, $O(n)$.

The standard, most robust approach for solving this problem involves the **Sliding Window technique**. This method utilizes two pointers, `left` and `right`, to dynamically define the current substring window. To ensure rapid checks for character uniqueness, a hash set (or a map) is used to track the characters currently residing within the window, leveraging its $O(1)$ average-time lookup capability. The `right` pointer iterates through the string, expanding the window one character at a time. As the window expands, the current length is continuously compared against and updates the global maximum length found so far.

The key to the $O(n)$ efficiency lies in how the algorithm handles duplicates. If the character at $s[right]$ is already present in the hash set, the uniqueness constraint is violated. Instead of discarding all previous work, the `left` pointer advances, removing characters from the left side of the window (and the hash set) until the duplicate character that caused the collision is finally removed. Once the window is again valid, the `right` pointer continues its forward movement. Because each character is visited by both the `left` and `right` pointers at most once, this single-pass, two-pointer strategy guarantees the sought-after $O(n)$ time complexity, making it the industry-standard solution.

##
##