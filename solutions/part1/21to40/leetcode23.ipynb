{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7821ff12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "class ListNode:\n",
    "    def __init__(self, val=0, next=None):\n",
    "        self.val = val\n",
    "        self.next = next\n",
    "\n",
    "def mergeKLists(lists: list[ListNode]) -> ListNode:\n",
    "    min_heap = []\n",
    "    \n",
    "    for i, head in enumerate(lists):\n",
    "        if head:\n",
    "            heapq.heappush(min_heap, (head.val, i, head))\n",
    "            \n",
    "    dummy = ListNode(0)\n",
    "    current = dummy\n",
    "    \n",
    "    while min_heap:\n",
    "        val, i, node = heapq.heappop(min_heap)\n",
    "        \n",
    "        current.next = node\n",
    "        current = current.next\n",
    "        \n",
    "        if node.next:\n",
    "            heapq.heappush(min_heap, (node.next.val, i, node.next))\n",
    "            \n",
    "    return dummy.next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c5e4dd",
   "metadata": {},
   "source": [
    "The LeetCode problem 23, \"Merge k Sorted Lists,\" is a classic algorithm challenge that requires merging $k$ separate, already sorted singly linked lists into a single, comprehensive sorted linked list. Given an array or list of $k$ linked list heads, the goal is to produce a new linked list that contains all the nodes from the original $k$ lists, ordered by their value. The efficiency of the solution is paramount, as a straightforward concatenation and sort would be too slow, typically failing due to time limit exceeded errors for large $k$ or long lists. \n",
    "\n",
    "---\n",
    "\n",
    "### **Brute Force (The Inefficient Approach)**\n",
    "\n",
    "A simple, but highly inefficient, approach is the \"Collect and Sort\" method. This involves traversing all $k$ linked lists and extracting every node's value into a single large array. Once all $N$ total values (where $N$ is the total number of nodes across all lists) are in the array, the array is sorted using a standard comparison-based sorting algorithm like Merge Sort or Quick Sort, taking $O(N \\log N)$ time. Finally, a new sorted linked list is constructed from the sorted array. While correct, this method doesn't take advantage of the crucial fact that the *input lists* are already sorted, which is a waste of pre-existing order and often too slow for competitive programming constraints.\n",
    "\n",
    "---\n",
    "\n",
    "### **The Iterative Two-List Merge Approach**\n",
    "\n",
    "A slightly better, though still suboptimal, approach is to iteratively merge the lists two at a time. This involves taking the first list and merging it with the second, then taking the resulting merged list and merging it with the third, and so on, until all $k$ lists have been merged into one final list. If we have $k$ lists, and each list has an average of $L$ nodes (so $N \\approx kL$), the total complexity would be roughly $O(k^2 L)$ or $O(k N)$ in the worst case, as the size of the list being merged grows linearly with each step. This approach performs better than the brute-force method by avoiding unnecessary intermediate sorting but is still too slow for large $k$.\n",
    "\n",
    "---\n",
    "\n",
    "### **The Divide and Conquer (Pairing) Approach**\n",
    "\n",
    "A more efficient method is the **Divide and Conquer** approach, which parallels the logic of Merge Sort. Instead of iteratively merging list 1 with list 2, then (1+2) with list 3, and so on, we pair up and merge the lists simultaneously. In the first step, we merge List 1 with List 2, List 3 with List 4, and so on. This reduces the number of lists by half (from $k$ to $k/2$) in a single pass. We repeat this process until only one merged list remains. The merging of two sorted lists, say of size $L_a$ and $L_b$, takes $O(L_a + L_b)$ time. Since we have $\\log k$ merge passes, and in each pass, we perform $O(N)$ total comparisons across all list merges, the overall time complexity is significantly improved to $O(N \\log k)$. This is generally the preferred approach when an $O(N \\log k)$ solution is required without using additional data structures.\n",
    "\n",
    "---\n",
    "\n",
    "### **The Priority Queue (Min-Heap) Approach: The Optimal Solution**\n",
    "\n",
    "The most elegant and often the most efficient solution in practice uses a **Min-Heap (Priority Queue)**. This approach simultaneously considers the head node of all $k$ lists. The Min-Heap stores the smallest available node from each of the $k$ lists.\n",
    "\n",
    "1.  **Initialization:** The heads of all non-empty lists are inserted into the Min-Heap. The heap organizes these $k$ nodes based on their value, with the smallest value always at the top.\n",
    "2.  **Extraction and Insertion Loop:**\n",
    "    a.  The node with the smallest value is **extracted** from the heap (this takes $O(\\log k)$ time).\n",
    "    b.  This smallest node is appended to the resulting merged list.\n",
    "    c.  If the extracted node had a `next` node in its original list, that `next` node is immediately **inserted** into the heap (also $O(\\log k)$ time).\n",
    "3.  **Termination:** This process repeats until the Min-Heap becomes empty, at which point all $N$ nodes have been processed and linked into the final sorted list.\n",
    "\n",
    "Since there are $N$ total nodes, and for each node, we perform an extraction and potentially an insertion, the total time complexity is $N \\times O(\\log k) = O(N \\log k)$. This achieves the same optimal time complexity as the Divide and Conquer method but is often conceptually simpler to implement and reason about.\n",
    "\n",
    "---\n",
    "\n",
    "### **Complexity Analysis**\n",
    "\n",
    "* **Time Complexity:** The optimal time complexity for both the Divide and Conquer and the Min-Heap approaches is $O(N \\log k)$, where $N$ is the total number of nodes across all lists, and $k$ is the number of lists.\n",
    "* **Space Complexity:** The Min-Heap approach requires $O(k)$ extra space to store the $k$ elements (one from each list) in the heap. The Divide and Conquer approach requires $O(1)$ extra space if performed in-place using existing nodes, or $O(N)$ to create new nodes, depending on the specific implementation constraints.\n",
    "\n",
    "Would you like a side-by-side comparison of the time complexities of the different approaches?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f474a4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
